- introduction to cuda architecture:
- implications on coding style (branches, thread divergence, coalescing)
- introduction to why we need multiple precision arithmetic (at least, for a predefined input size)
- presentation of operations needed (addition, subtraction, multiplication, and their modular counterparts)
- implementation of operations, with detailed graph of each one, and with a specific output of the python script for each
- effect of memory access patterns on performance (coalesced vs non-coalesced)
- benchmarks
- testing framework
